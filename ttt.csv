"import gym
from gym import spaces
import numpy as np

class TicTacToeEnv(gym.Env):
    def __init__(self):
        self.board = np.zeros((3, 3))
        self.current_player = 1
        self.action_space = spaces.Discrete(9)
        self.observation_space = spaces.Box(low=-1, high=1, shape=(3, 3), dtype=np.float32)
    
    def reset(self):
        self.board = np.zeros((3, 3))
        self.current_player = 1
        return self.board
    
    def step(self, action):
        x = action // 3
        y = action % 3
        if self.board[x][y] != 0:
            return self.board, -1, False, {}
        
        self.board[x][y] = self.current_player
        
        if self.check_winner():
            return self.board, 1, True, {}
        
        if self.check_draw():
            return self.board, 0, True, {}
        
        self.current_player = -self.current_player
        return self.board, 0, False, {}
    
    def check_winner(self):
        for i in range(3):
            if self.board[i][0] == self.board[i][1] == self.board[i][2] != 0:
                return True
            if self.board[0][i] == self.board[1][i] == self.board[2][i] != 0:
                return True
        if self.board[0][0] == self.board[1][1] == self.board[2][2] != 0:
            return True
        if self.board[2][0] == self.board[1][1] == self.board[0][2] != 0:
            return True
        return False
    
    def check_draw(self):
        return np.all(self.board != 0) and not self.check_winner()
    
    def render(self, mode='console'):
        if mode != 'console':
            raise NotImplementedError()
        print(self.board)
        
env = TicTacToeEnv()
observation = env.reset()
done = False
while not done:
    env.render()
    action = env.action_space.sample()
    observation, reward, done, info = env.step(action)
    print(reward)
env.render()"
