"import numpy as np

class QLearner:
    def _init_(self, env, num_actions):
        self.env = env
        self.num_actions = num_actions
        self.Q = np.zeros((env.observation_space.n, env.action_space.n))

    def get_action(self, state):
        q_values = self.Q[state]
        action = np.argmax(q_values)
        return action

    def learn(self, state, action, reward, next_state):
        self.Q[state][action] += self.alpha * (reward + self.gamma * np.max(self.Q[next_state]) - self.Q[state][action])

    def train(self, num_episodes):
        for episode in range(num_episodes):
            state = self.env.reset()
            while not self.env.done:
                action = self.get_action(state)
                next_state, reward, done, _ = self.env.step(action)
                self.learn(state, action, reward, next_state)
                state = next_state"
